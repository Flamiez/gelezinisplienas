{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, yaml, random, cv2, gc, torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "SEED = 321 # 123, 999\n",
    "BASE = r\"C:\\Users\\Think\\Desktop\\NesvarbuSefoSpecialusHomemade\"\n",
    "REAL = os.path.join(BASE, r\"Datasets\\UAV 1_Resized_512\")\n",
    "SYNTH_DIRS = [\n",
    "    os.path.join(BASE, r\"Datasets\\GeneratedImagesEimis\"),\n",
    "    os.path.join(BASE, r\"Datasets\\GeneratedImagesVilius\"),\n",
    "    os.path.join(BASE, r\"Datasets\\GeneratedImagesJokubas\")\n",
    "]\n",
    "SPLIT_DIR = os.path.join(BASE, f\"app\\Final_Data_Splits_Seed{SEED}\")\n",
    "RUNS_DIR = os.path.join(BASE, f\"app\\Final_Training_Runs_Seed{SEED}\")\n",
    "os.makedirs(SPLIT_DIR, exist_ok=True)\n",
    "\n",
    "# aug\n",
    "NO_AUG = {'hsv_h': 0, 'hsv_s': 0, 'hsv_v': 0, 'degrees': 0, 'translate': 0, 'scale': 0, 'shear': 0, \n",
    "          'perspective': 0, 'flipud': 0, 'fliplr': 0, 'mosaic': 0, 'mixup': 0, 'copy_paste': 0, 'erasing': 0}\n",
    "HEAVY_AUG = {'degrees': 45, 'translate': 0.3, 'scale': 0.8, 'shear': 5, 'flipud': 0.5, 'fliplr': 0.5, \n",
    "             'mosaic': 1.0, 'mixup': 0.2, 'copy_paste': 0.3, 'erasing': 0.4, 'hsv_h': 0.05, 'hsv_s': 0.8, 'hsv_v': 0.6}\n",
    "\n",
    "# DATA PREP \n",
    "def get_syn(dirs):\n",
    "    valid = []\n",
    "    for d in dirs:\n",
    "        md = os.path.join(d, \"GeneratedMasks\")\n",
    "        for p in glob.glob(os.path.join(d, \"GeneratedImages\", \"*.*\")):\n",
    "            t = os.path.splitext(p)[0] + \".txt\"\n",
    "            if os.path.exists(t) and os.path.getsize(t) > 0: valid.append(p); continue\n",
    "            m = os.path.join(md, os.path.basename(p).replace(os.path.splitext(p)[1], \".png\"))\n",
    "            if not os.path.exists(m): continue\n",
    "            msk, img = cv2.imread(m, 0), cv2.imread(p)\n",
    "            if msk is None or img is None: continue\n",
    "            cts, _ = cv2.findContours(msk, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if not cts: continue\n",
    "            lines = []\n",
    "            h, w = img.shape[:2]\n",
    "            for c in cts:\n",
    "                if cv2.contourArea(c) > 10:\n",
    "                    x, y, bw, bh = cv2.boundingRect(c)\n",
    "                    lines.append(f\"0 {(x+bw/2)/w:.6f} {(y+bh/2)/h:.6f} {bw/w:.6f} {bh/h:.6f}\")\n",
    "            if not lines: continue\n",
    "            with open(t, \"w\") as f: f.write(\"\\n\".join(lines))\n",
    "            valid.append(p)\n",
    "    return valid\n",
    "\n",
    "real = [os.path.abspath(p) for p in glob.glob(os.path.join(REAL, \"images\", \"train\", \"*.*\"))]\n",
    "syn = get_syn(SYNTH_DIRS)\n",
    "with open(os.path.join(SPLIT_DIR, \"val.txt\"), \"w\") as f: f.write(\"\\n\".join([os.path.abspath(p) for p in glob.glob(os.path.join(REAL, \"images\", \"valid\", \"*.*\"))]))\n",
    "\n",
    "def make_cfg(name, files):\n",
    "    with open(os.path.join(SPLIT_DIR, f\"{name}.txt\"), \"w\") as f: f.write(\"\\n\".join(files))\n",
    "    with open(os.path.join(SPLIT_DIR, f\"{name}.yaml\"), \"w\") as f: yaml.dump({'path': SPLIT_DIR, 'train': f\"{name}.txt\", 'val': \"val.txt\", 'names': {0: 'building'}}, f)\n",
    "\n",
    "N = len(real)\n",
    "random.seed(SEED)\n",
    "make_cfg(\"real100_only\", random.sample(real, N))\n",
    "make_cfg(\"multi_syn100_real0\", random.sample(syn, N))\n",
    "\n",
    "for p in [25, 50, 75]:\n",
    "    nr, ns = int(N * p/100), N - int(N * p/100)\n",
    "    random.seed(SEED); sub_r = random.sample(real, nr)\n",
    "    make_cfg(f\"real{p}_only\", sub_r)\n",
    "    random.seed(SEED); make_cfg(f\"multi_syn{100-p}_real{p}\", sub_r + random.sample(syn, ns))\n",
    "\n",
    "runs = [\n",
    "    (\"real100_only\", \"real100_only\", {}),\n",
    "    (\"real100_only\", \"yolo11s_2_default_aug\", {}),\n",
    "    (\"real100_only\", \"yolo11s_3_heavy_aug\", HEAVY_AUG),\n",
    "    (\"real100_only\", \"yolo11s_1_no_aug\", NO_AUG),\n",
    "    (\"real75_only\", \"real75_only\", {}),\n",
    "    (\"real50_only\", \"real50_only\", {}),\n",
    "    (\"real25_only\", \"real25_only\", {}),\n",
    "    (\"multi_syn25_real75\", \"multi_syn25_real75\", NO_AUG),\n",
    "    (\"multi_syn50_real50\", \"multi_syn50_real50\", NO_AUG),\n",
    "    (\"multi_syn75_real25\", \"multi_syn75_real25\", NO_AUG),\n",
    "    (\"multi_syn100_real0\", f\"yolo11s_multi_syn100_real0_seed{SEED}\", NO_AUG)\n",
    "]\n",
    "\n",
    "for cfg, name, kw in runs:\n",
    "    if \"seed\" not in name and \"yolo\" not in name: name += f\"_seed{SEED}\"\n",
    "    if os.path.exists(os.path.join(RUNS_DIR, name, \"weights\", \"best.pt\")): \n",
    "        print(f\"Skipping {name}\"); continue\n",
    "    \n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        model = YOLO(\"yolo11s.pt\")\n",
    "        model.train(\n",
    "            data=os.path.join(SPLIT_DIR, f\"{cfg}.yaml\"), \n",
    "            project=RUNS_DIR, name=name, \n",
    "            epochs=100, \n",
    "            imgsz=640, \n",
    "            batch=-1,       \n",
    "            workers=2,      \n",
    "            cache=True,     \n",
    "            val=False,      \n",
    "            plots=False, \n",
    "            seed=SEED, **kw)\n",
    "    except Exception as e: print(f\"Error {name}: {e}\")\n",
    "    finally: del model; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, shutil, pandas as pd, gc, torch\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "SEED = 321 # 123, 999\n",
    "BASE = r\"C:\\Users\\Think\\Desktop\\NesvarbuSefoSpecialusHomemade\"\n",
    "REAL_VAL = os.path.join(BASE, r\"Datasets\\UAV 1_Resized_512\\dataset.yaml\")\n",
    "RWDS_ROOT = r\"C:\\Users\\Think\\Desktop\\RWDS\\RWDS_Dataset\\RWDS_Dataset\\RWDS_FR\\train\"\n",
    "OUT_RWDS = r\"C:\\Users\\Think\\Desktop\\RWDS_Flooding_YOLO\"\n",
    "RUNS_DIR = os.path.join(BASE, f\"app\\Final_Training_Runs_Seed{SEED}\")\n",
    "EXCEL_PATH = os.path.join(BASE, f\"app\\Results_Seed{SEED}.xlsx\")\n",
    "\n",
    "def prep_rwds():\n",
    "    os.makedirs(os.path.join(OUT_RWDS, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUT_RWDS, \"labels\"), exist_ok=True)\n",
    "    yaml_p = os.path.join(OUT_RWDS, \"rwds.yaml\")\n",
    "    if not os.path.exists(yaml_p):\n",
    "        with open(yaml_p, \"w\") as f: f.write(f\"path: {OUT_RWDS}\\ntrain: images\\nval: images\\nnames:\\n  0: building\")\n",
    "    if len(os.listdir(os.path.join(OUT_RWDS, \"images\"))) > 100: return yaml_p\n",
    "    jsons = [\"Flooding_Group_combined_train_512_02.json\", \"Flooding_Group_India_train_512_02.json\", \"Flooding_Group_US_train_512_02.json\"]\n",
    "    for j in jsons:\n",
    "        p = os.path.join(RWDS_ROOT, j)\n",
    "        if not os.path.exists(p): continue\n",
    "        with open(p, 'r') as f: data = json.load(f)\n",
    "        imgs = {i['id']: i for i in data['images']}\n",
    "        for a in tqdm(data['annotations'], desc=j):\n",
    "            im = imgs.get(a['image_id'])\n",
    "            if not im: continue\n",
    "            fn = im['file_name']\n",
    "            src = os.path.join(RWDS_ROOT, fn)\n",
    "            if not os.path.exists(src):\n",
    "                for r, _, fs in os.walk(RWDS_ROOT):\n",
    "                    if fn in fs: src = os.path.join(r, fn); break\n",
    "            if os.path.exists(src):\n",
    "                dst = os.path.join(OUT_RWDS, \"images\", fn)\n",
    "                if not os.path.exists(dst): shutil.copy2(src, dst)\n",
    "                h, w = im['height'], im['width']\n",
    "                x, y, bw, bh = a['bbox']\n",
    "                with open(os.path.join(OUT_RWDS, \"labels\", os.path.splitext(fn)[0] + \".txt\"), \"a\") as f:\n",
    "                    f.write(f\"0 {(x+bw/2)/w:.6f} {(y+bh/2)/h:.6f} {bw/w:.6f} {bh/h:.6f}\\n\")\n",
    "    return yaml_p\n",
    "\n",
    "rwds_cfg = prep_rwds()\n",
    "results = []\n",
    "\n",
    "if not os.path.exists(RUNS_DIR):\n",
    "    print(\"Runs directory not found.\")\n",
    "else:\n",
    "    # scan\n",
    "    models = []\n",
    "    for d in os.listdir(RUNS_DIR):\n",
    "        w = os.path.join(RUNS_DIR, d, \"weights\", \"best.pt\")\n",
    "        if os.path.exists(w): models.append((d, w))\n",
    "    \n",
    "    print(f\"Found {len(models)} models.\")\n",
    "    for m_name, w in models:\n",
    "        print(f\"Testing {m_name}...\")\n",
    "        try:\n",
    "            model = YOLO(w)\n",
    "            r_orig = model.val(data=REAL_VAL, split='val', batch=32, device=0, half=True, plots=False, verbose=False)\n",
    "            r_rwds = model.val(data=rwds_cfg, split='val', batch=32, device=0, half=True, plots=False, verbose=False)\n",
    "            results.append({\n",
    "                \"Model\": m_name,\n",
    "                \"Orig_mAP50\": r_orig.box.map50, \"Orig_mAP50-95\": r_orig.box.map, \"Orig_P\": r_orig.box.mp, \"Orig_R\": r_orig.box.mr,\n",
    "                \"RWDS_mAP50\": r_rwds.box.map50, \"RWDS_mAP50-95\": r_rwds.box.map, \"RWDS_P\": r_rwds.box.mp, \"RWDS_R\": r_rwds.box.mr\n",
    "            })\n",
    "        except Exception as e: print(f\"Fail {m_name}: {e}\")\n",
    "        finally: del model; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_excel(EXCEL_PATH, index=False)\n",
    "    print(f\"Saved to {EXCEL_PATH}\")\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P170M109",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
